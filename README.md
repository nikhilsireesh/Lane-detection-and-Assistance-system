# ğŸš— Lane Detection and Assistance System Using CNN

![Lane Detection](https://img.shields.io/badge/Accuracy->90%25-brightgreen)
![Real-time](https://img.shields.io/badge/Inference-15ms-blue)
![Model Size](https://img.shields.io/badge/Parameters-7.8M-orange)
![Status](https://img.shields.io/badge/Status-Production%20Ready-success)

## ğŸ¯ Project Overview

**Advanced computer vision system for autonomous vehicle safety**, implementing deep learning techniques for real-time lane detection and driver assistance. This comprehensive system combines cutting-edge CNN architecture with practical deployment solutions.

### ğŸ† Key Achievements
- **>90% Detection Accuracy** - Validated on diverse road conditions
- **15ms Inference Time** - Real-time processing capability
- **7.8M Parameter Model** - Lightweight U-Net architecture
- **Complete Web Interface** - Professional ADAS-style system
- **Driver Assistance Integration** - 4-level safety alert system

## ğŸš€ Quick Start Guide

### ğŸ”§ System Requirements
- **Python 3.9+**
- **TensorFlow 2.17+**
- **OpenCV 4.x**
- **Flask** (for web interface)
- **macOS/Windows/Linux**

### ğŸ“¦ Installation

1. **Clone the Repository**
```bash
git clone <repository-url>
cd "Lane detection and Assistance system using CNN"
```

2. **Install Dependencies**
```bash
# Core requirements
pip install tensorflow opencv-python flask pillow numpy

# Optional: Create virtual environment (recommended)
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate     # Windows
```

3. **Verify Installation**
```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
python -c "import cv2; print('OpenCV:', cv2.__version__)"
```

## ğŸ® Running the System

### ğŸŒ Web Application (Recommended)

**Start the complete lane detection web interface:**

```bash
# Navigate to Phase 7
cd "phase7_real_time_processing/scripts"

# Launch web application
python web_demo.py
```

**Access the system at:** http://localhost:5001

### ğŸ“± Features Available:
- âœ… **Live Camera Processing** - Real-time lane detection
- âœ… **Image Upload & Analysis** - Static image processing
- âœ… **Video Processing** - Batch video analysis with overlays
- âœ… **Driver Assistance Dashboard** - Safety metrics and alerts
- âœ… **Performance Statistics** - Real-time system monitoring

### ğŸ¥ Camera Permissions (macOS)
If camera access is denied:
```bash
# Reset camera permissions
tccutil reset Camera

# Or manually: System Preferences â†’ Security & Privacy â†’ Camera
```

### ğŸ“Š Individual Phase Execution

#### Phase 1: Dataset Analysis
```bash
cd phase1_dataset_analysis/scripts
python enhanced_analysis.py
```

#### Phase 2: Data Preprocessing
```bash
cd phase2_data_preprocessing/scripts
python preprocess_data.py
```

#### Phase 3: Model Architecture
```bash
cd phase3_model_architecture/scripts
python build_model.py
```

#### Phase 4: Model Training
```bash
cd phase4_model_training/scripts
python train_model.py
```

#### Phase 5: Model Validation
```bash
cd phase5_model_validation/scripts
python validate_model.py
```

## ğŸ“ Project Structure

```
Lane detection and Assistance system using CNN/
â”œâ”€â”€ ğŸ“Š Dataset/                          # Training data
â”‚   â”œâ”€â”€ train_dataset.p                  # Training images (12,764 samples)
â”‚   â””â”€â”€ labels_dataset.p                 # Binary lane masks
â”‚
â”œâ”€â”€ ğŸ” phase1_dataset_analysis/          # Data exploration and analysis
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ enhanced_analysis.py         # Comprehensive dataset analysis
â”‚       â””â”€â”€ reports/                     # Analysis reports and visualizations
â”‚
â”œâ”€â”€ ğŸ”„ phase2_data_preprocessing/        # Data preparation pipeline
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ preprocess_data.py          # Normalization and augmentation
â”‚       â””â”€â”€ reports/                     # Preprocessing reports
â”‚
â”œâ”€â”€ ğŸ—ï¸ phase3_model_architecture/        # CNN architecture design
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ build_model.py              # Lightweight U-Net implementation
â”‚       â”œâ”€â”€ models/                     # Saved model architectures
â”‚       â””â”€â”€ visualizations/             # Architecture diagrams
â”‚
â”œâ”€â”€ ğŸ¯ phase4_model_training/            # Model training pipeline
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ train_model.py              # Training with callbacks
â”‚       â”œâ”€â”€ models/                     # Trained models
â”‚       â””â”€â”€ visualizations/             # Training plots
â”‚
â”œâ”€â”€ ğŸ“ˆ phase5_model_validation/          # Performance evaluation
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ validate_model.py           # Comprehensive validation
â”‚       â”œâ”€â”€ outputs/                    # Validation results
â”‚       â””â”€â”€ visualizations/             # Performance charts
â”‚
â”œâ”€â”€ âš¡ phase6_inference_pipeline/        # Real-time inference
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ inference_demo.py           # Live inference demo
â”‚       â””â”€â”€ inference_results/          # Benchmark results
â”‚
â”œâ”€â”€ ğŸ¥ phase7_real_time_processing/      # Web application
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ web_demo.py                 # Flask web application
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html                  # Web interface
â”‚   â””â”€â”€ uploads/                        # User uploaded files
â”‚
â”œâ”€â”€ ğŸ“„ phase9_project_report/            # Documentation and reports
â”‚   â”œâ”€â”€ presentation_comprehensive.html  # 15-page presentation
â”‚   â”œâ”€â”€ project_report.html             # Detailed project report
â”‚   â”œâ”€â”€ assets/                         # Images and diagrams
â”‚   â””â”€â”€ README.md                       # Project documentation
â”‚
â”œâ”€â”€ ğŸ“‹ requirements/                     # Phase-specific dependencies
â”œâ”€â”€ âš™ï¸ project_config.json              # Project configuration
â””â”€â”€ ğŸ“– README.md                        # This file
```

## ğŸ”§ Technical Specifications

### ğŸ§  Model Architecture
- **Type:** Lightweight U-Net
- **Parameters:** 7,760,097 (7.8M)
- **Input Shape:** 80Ã—160Ã—3 RGB images
- **Output Shape:** 80Ã—160Ã—1 binary lane mask
- **Architecture Depth:** 32 layers with skip connections

### ğŸ“Š Dataset Details
- **Total Images:** 12,764 road scenes
- **Training Split:** 10,211 samples (80%)
- **Validation Split:** 2,553 samples (20%)
- **Resolution:** 80Ã—160 pixels (optimized for real-time)
- **Normalization:** [0.0, 1.0] range
- **Binary Threshold:** 240 for lane segmentation

### âš¡ Performance Metrics
- **Accuracy:** >90% (validated)
- **IoU Score:** >90%
- **Precision:** >90%
- **Recall:** >90%
- **F1 Score:** >90%
- **Inference Time:** 15ms (batch processing)
- **Real-time Capability:** 60+ FPS

## ğŸ¯ Applications & Use Cases

### ğŸš— Automotive Industry
- **Autonomous Vehicles** - Self-driving car guidance and path planning
- **ADAS Systems** - Advanced Driver Assistance Systems integration
- **Lane Keeping Assist** - Real-time lane departure warnings
- **Fleet Management** - Commercial vehicle safety monitoring

### ğŸ™ï¸ Smart City & Infrastructure
- **Traffic Monitoring** - Automated traffic flow analysis
- **Road Maintenance** - Lane marking condition assessment
- **Safety Analytics** - Accident prevention and analysis
- **Urban Planning** - Road infrastructure optimization

### ğŸ“± Driver Assistance Features
- **4-Level Alert System:**
  - ğŸ”´ **Critical** - Immediate correction required
  - ğŸŸ¡ **Warning** - Approaching danger zone
  - ğŸŸ¢ **Safe** - Normal driving conditions  
  - ğŸ”µ **Excellent** - Optimal lane positioning

## ğŸ¨ Web Interface Features

### ğŸ“¸ Input Methods
- **Live Camera Feed** - Real-time processing with camera
- **Image Upload** - Drag & drop or browse image files
- **Video Upload** - Process video files with lane overlays
- **Batch Processing** - Multiple file processing

### ğŸ“Š Dashboard Components
- **Real-time Statistics** - Processing speed and accuracy metrics
- **Assistance Dashboard** - Safety alerts and lane positioning
- **Performance Monitor** - System resource usage
- **Results Gallery** - Processed images and videos

## ğŸ› ï¸ Development & Customization

### ğŸ”§ Configuration
Edit `project_config.json` for:
- Model parameters and thresholds
- Training hyperparameters
- Input/output specifications
- Performance targets

### ğŸ“ Adding New Features
1. **Custom Models** - Implement in `phase3_model_architecture/`
2. **New Preprocessing** - Add to `phase2_data_preprocessing/`
3. **UI Enhancements** - Modify `phase7_real_time_processing/templates/`
4. **API Extensions** - Extend `web_demo.py` endpoints

## ğŸ› Troubleshooting

### Common Issues & Solutions

**Camera Access Denied (macOS):**
```bash
tccutil reset Camera
# Then restart the application
```

**Module Import Errors:**
```bash
pip install --upgrade tensorflow opencv-python flask
```

**Performance Issues:**
- Reduce batch size in training
- Use CPU-optimized inference
- Check available system memory

**Web Interface Not Loading:**
- Verify port 5001 is available
- Check firewall settings
- Ensure all dependencies are installed

## ğŸ“ˆ Project Roadmap

### âœ… Completed Features
- [x] Complete 8-phase development pipeline
- [x] Lightweight U-Net architecture (>90% accuracy)
- [x] Real-time web application
- [x] Driver assistance system
- [x] Professional documentation

### ğŸš§ Future Enhancements
- [ ] Multi-lane detection and classification
- [ ] Integration with other ADAS systems
- [ ] Mobile application development
- [ ] Edge device optimization
- [ ] Advanced weather condition handling

## ğŸ“š Documentation

- **ğŸ“Š Comprehensive Presentation:** `phase9_project_report/presentation_comprehensive.html`
- **ğŸ“„ Detailed Report:** `phase9_project_report/project_report.html`
- **ğŸ” Phase Reports:** Individual reports in each phase directory
- **ğŸ“– Technical Specs:** Available in project documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Project Lead** - Lane Detection and Assistance System Development
- **Technical Implementation** - Deep Learning and Computer Vision

## ğŸ™ Acknowledgments

- TensorFlow team for the deep learning framework
- OpenCV community for computer vision tools
- Research community for U-Net architecture innovations
- Open source contributors for various dependencies

---

**ğŸš€ Ready to revolutionize lane detection? Start with our web demo at http://localhost:5001**

*For questions or support, please refer to the comprehensive documentation in the `phase9_project_report/` directory.*
